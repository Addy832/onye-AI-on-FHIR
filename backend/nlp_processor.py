"""
BioBERT-Based Healthcare Query Entity Extraction
Completely replaces rule-based approach with BioBERT for semantic feature extraction
and medical entity recognition in healthcare queries.
"""

import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel, pipeline
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
import logging
import json
import re
from dataclasses import dataclass
import asyncio

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MedicalEntity:
    """Medical entity extracted by BioBERT"""
    text: str
    entity_type: str  # CONDITION, MEDICATION, PROCEDURE, etc.
    confidence: float
    start_pos: int
    end_pos: int
    icd_code: Optional[str] = None
    snomed_code: Optional[str] = None
    umls_cui: Optional[str] = None

@dataclass
class QuerySemantics:
    """Semantic understanding of the query"""
    intent: str
    confidence: float
    action_type: str
    target_resource: str
    modifiers: Dict[str, Any]

class BioBERTHealthcareNLP:
    """
    Advanced BioBERT-based NLP processor for healthcare queries.
    Completely replaces rule-based pattern matching with semantic understanding.
    """
    
    def __init__(self):
        self.biobert_model_name = "dmis-lab/biobert-v1.1"
        self.clinical_bert_name = "emilyalsentzer/Bio_ClinicalBERT"
        
        # Initialize models
        self.tokenizer = None
        self.biobert_model = None
        self.sentence_transformer = None
        self.ner_pipeline = None
        
        # Medical knowledge base
        self.medical_ontology = self._load_medical_ontology()
        self.condition_embeddings = {}
        self.intent_templates = self._create_intent_templates()
        
        # Semantic similarity thresholds
        self.condition_threshold = 0.50  # Lowered from 0.75 to catch more conditions
        self.intent_threshold = 0.70
        self.demographic_threshold = 0.65
        
        # Initialize BioBERT models
        self._initialize_biobert_models()
        
        # Pre-compute medical concept embeddings
        self._precompute_medical_embeddings()
    
    def _initialize_biobert_models(self):
        """Initialize BioBERT models for semantic processing"""
        try:
            logger.info("üîÑ Loading BioBERT models...")
            
            # Primary BioBERT model for general medical understanding
            self.tokenizer = AutoTokenizer.from_pretrained(self.biobert_model_name)
            self.biobert_model = AutoModel.from_pretrained(self.biobert_model_name)
            
            # Sentence transformer for efficient embeddings
            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')
            
            # NER pipeline for medical entity recognition
            try:
                self.ner_pipeline = pipeline(
                    "ner",
                    model="d4data/biomedical-ner-all",
                    tokenizer="d4data/biomedical-ner-all",
                    aggregation_strategy="simple"
                )
                logger.info("‚úÖ Biomedical NER pipeline loaded")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Biomedical NER not available: {e}")
                # Fallback to general NER
                self.ner_pipeline = pipeline("ner", aggregation_strategy="simple")
            
            logger.info("‚úÖ BioBERT models loaded successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load BioBERT models: {e}")
            raise RuntimeError(f"BioBERT initialization failed: {e}")
    
    def _load_medical_ontology(self) -> Dict[str, Dict]:
        """Load comprehensive medical ontology with embeddings"""
        return {
            # Endocrine conditions
            "diabetes_mellitus": {
                "icd10": "E11.9",
                "snomed": "44054006",
                "umls": "C0011860",
                "synonyms": ["diabetes", "diabetic", "DM", "diabetes mellitus", "hyperglycemia", 
                           "insulin resistance", "type 2 diabetes", "NIDDM", "adult onset diabetes"],
                "category": "endocrine",
                "description": "diabetes mellitus metabolic disorder glucose insulin"
            },
            "diabetic_ketoacidosis": {
                "icd10": "E10.10",
                "snomed": "420422005", 
                "umls": "C0011880",
                "synonyms": ["DKA", "ketoacidosis", "diabetic coma"],
                "category": "endocrine",
                "description": "diabetic ketoacidosis emergency hyperglycemia ketones"
            },
            
            # Cardiovascular conditions
            "hypertension": {
                "icd10": "I10",
                "snomed": "38341003",
                "umls": "C0020538",
                "synonyms": ["high blood pressure", "HTN", "hypertensive", "elevated BP", 
                           "arterial hypertension", "essential hypertension"],
                "category": "cardiovascular",
                "description": "hypertension high blood pressure cardiovascular systolic diastolic"
            },
            "myocardial_infarction": {
                "icd10": "I21.9",
                "snomed": "22298006",
                "umls": "C0027051", 
                "synonyms": ["myocardial infarction", "heart attack", "MI", "myocardial infarct", "cardiac infarction",
                           "coronary thrombosis", "heart failure acute", "acute MI", "STEMI", "NSTEMI"],
                "category": "cardiovascular",
                "description": "myocardial infarction heart attack cardiac emergency coronary MI"
            },
            "atrial_fibrillation": {
                "icd10": "I48.91",
                "snomed": "49436004",
                "umls": "C0004238",
                "synonyms": ["AFib", "A-fib", "atrial fib", "irregular heartbeat", "arrhythmia"],
                "category": "cardiovascular", 
                "description": "atrial fibrillation arrhythmia irregular heart rhythm cardiac"
            },
            "cardiovascular_disease": {
                "icd10": "I25.10",
                "snomed": "49601007",
                "umls": "C0007222",
                "synonyms": ["cardiovascular disease", "heart disease", "cardiac disease", "CVD", 
                           "coronary artery disease", "CAD", "coronary heart disease", "CHD",
                           "ischemic heart disease", "IHD", "cardiac condition", "heart condition"],
                "category": "cardiovascular",
                "description": "cardiovascular disease heart cardiac coronary artery atherosclerosis"
            },
            
            # Respiratory conditions
            "chronic_obstructive_pulmonary_disease": {
                "icd10": "J44.1",
                "snomed": "13645005",
                "umls": "C0024117",
                "synonyms": ["COPD", "emphysema", "chronic bronchitis", "obstructive lung disease",
                           "respiratory failure chronic"],
                "category": "respiratory",
                "description": "COPD chronic obstructive pulmonary disease emphysema bronchitis"
            },
            "asthma": {
                "icd10": "J45.9",
                "snomed": "195967001",
                "umls": "C0004096",
                "synonyms": ["bronchial asthma", "allergic asthma", "exercise induced asthma",
                           "wheezing", "bronchospasm"],
                "category": "respiratory",
                "description": "asthma bronchial allergic respiratory wheezing bronchospasm"
            },
            "pneumonia": {
                "icd10": "J15.9",
                "snomed": "233604007",
                "umls": "C0032285",
                "synonyms": ["lung infection", "pneumonitis", "bacterial pneumonia", 
                           "viral pneumonia", "respiratory infection"],
                "category": "respiratory",
                "description": "pneumonia lung infection respiratory bacterial viral"
            },
            
            # Mental health conditions  
            "major_depressive_disorder": {
                "icd10": "F32.9",
                "snomed": "370143000",
                "umls": "C1269683",
                "synonyms": ["depression", "major depression", "MDD", "depressive episode",
                           "clinical depression", "unipolar depression"],
                "category": "mental_health",
                "description": "depression major depressive disorder mental health mood"
            },
            "generalized_anxiety_disorder": {
                "icd10": "F41.1", 
                "snomed": "21897009",
                "umls": "C0270549",
                "synonyms": ["anxiety", "GAD", "anxiety disorder", "generalized anxiety",
                           "panic disorder", "social anxiety"],
                "category": "mental_health",
                "description": "anxiety generalized anxiety disorder mental health panic"
            },
            
            # Musculoskeletal conditions
            "rheumatoid_arthritis": {
                "icd10": "M06.9",
                "snomed": "69896004", 
                "umls": "C0003873",
                "synonyms": ["RA", "rheumatoid", "arthritis", "joint inflammation",
                           "autoimmune arthritis", "inflammatory arthritis"],
                "category": "musculoskeletal",
                "description": "rheumatoid arthritis autoimmune joint inflammation"
            },
            "osteoarthritis": {
                "icd10": "M19.9",
                "snomed": "396275006",
                "umls": "C0029408",
                "synonyms": ["OA", "degenerative arthritis", "joint degeneration",
                           "wear and tear arthritis"],
                "category": "musculoskeletal", 
                "description": "osteoarthritis degenerative joint disease wear tear"
            },
            
            # Cancer conditions
            "lung_cancer": {
                "icd10": "C78.00",
                "snomed": "363358000",
                "umls": "C0242379",
                "synonyms": ["lung cancer", "lung carcinoma", "bronchogenic carcinoma", "pulmonary cancer",
                           "lung tumor", "lung neoplasm", "cancer of the lung", "lung malignancy"],
                "category": "oncology",
                "description": "lung cancer carcinoma bronchogenic pulmonary neoplasm"
            },
            "breast_cancer": {
                "icd10": "C50.9",
                "snomed": "254837009",
                "umls": "C0006142", 
                "synonyms": ["breast carcinoma", "mammary cancer", "breast tumor",
                           "breast neoplasm", "mammary carcinoma"],
                "category": "oncology",
                "description": "breast cancer carcinoma mammary neoplasm tumor"
            },
            
            # Neurological conditions
            "stroke": {
                "icd10": "I64",
                "snomed": "230690007",
                "umls": "C0038454",
                "synonyms": ["cerebrovascular accident", "CVA", "brain attack", "cerebral infarction",
                           "hemorrhagic stroke", "ischemic stroke"],
                "category": "neurological",
                "description": "stroke cerebrovascular accident brain CVA neurological"
            },
            "alzheimer_disease": {
                "icd10": "G30.9",
                "snomed": "26929004",
                "umls": "C0002395",
                "synonyms": ["Alzheimer's", "dementia", "cognitive decline", "memory loss",
                           "neurodegenerative disease"],
                "category": "neurological",
                "description": "Alzheimer disease dementia cognitive decline memory neurodegenerative"
            }
        }
    
    def _create_intent_templates(self) -> Dict[str, Dict]:
        """Create intent classification templates"""
        return {
            "search_patients": {
                "templates": [
                    "Find patients with medical condition",
                    "Show me patients diagnosed with disease", 
                    "List patients having symptoms",
                    "Display patients with clinical condition",
                    "Get patients with diagnosis"
                ],
                "action": "search",
                "resource": "Patient",
                "confidence_boost": 0.1
            },
            "count_patients": {
                "templates": [
                    "Count patients with condition",
                    "How many patients have disease",
                    "Number of patients diagnosed with",
                    "Total patients with medical condition", 
                    "Enumerate patients having"
                ],
                "action": "count", 
                "resource": "Patient",
                "confidence_boost": 0.15
            },
            "analyze_conditions": {
                "templates": [
                    "Analyze patient conditions and outcomes",
                    "Study disease patterns in population",
                    "Examine clinical trends and statistics",
                    "Investigate medical condition relationships",
                    "Research patient data and correlations"
                ],
                "action": "analyze",
                "resource": "Condition", 
                "confidence_boost": 0.2
            },
            "compare_treatments": {
                "templates": [
                    "Compare treatment effectiveness",
                    "Evaluate therapy outcomes", 
                    "Analyze medication responses",
                    "Study intervention results",
                    "Compare clinical approaches"
                ],
                "action": "compare",
                "resource": "MedicationStatement",
                "confidence_boost": 0.2
            }
        }
    
    def _precompute_medical_embeddings(self):
        """Pre-compute embeddings for medical concepts"""
        logger.info("üîÑ Pre-computing medical concept embeddings...")
        
        for concept, data in self.medical_ontology.items():
            # Create rich text representation
            concept_text = f"{concept} {data['description']} {' '.join(data['synonyms'])}"
            
            # Generate embedding
            embedding = self._get_embedding(concept_text)
            self.condition_embeddings[concept] = {
                'embedding': embedding,
                'metadata': data
            }
        
        logger.info(f"‚úÖ Pre-computed {len(self.condition_embeddings)} medical concept embeddings")
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """
        Process healthcare query using BioBERT semantic understanding.
        Completely replaces rule-based approach.
        
        Args:
            query (str): Natural language healthcare query
            
        Returns:
            Dict containing extracted entities and FHIR parameters
        """
        logger.info(f"üß¨ Processing query with BioBERT: {query}")
        
        # Step 0: Extract RAW BioBERT entities to showcase full model capabilities
        raw_biobert_entities = self._extract_raw_biobert_entities(query)
        
        # Step 1: Extract medical entities using BioBERT NER
        medical_entities = self._extract_medical_entities(query)
        
        # Step 2: Classify query intent using semantic similarity
        query_semantics = self._classify_query_intent(query)
        
        # Step 3: Extract demographics using BioBERT embeddings
        demographics = self._extract_demographics_semantic(query)
        
        # Step 4: Extract temporal information semantically
        temporal_info = self._extract_temporal_semantic(query)
        
        # Step 5: Extract numerical constraints (ages, counts)
        numerical_constraints = self._extract_numerical_constraints(query)
        
        # Step 6: Map to medical conditions using semantic similarity
        conditions = self._map_to_medical_conditions(query, medical_entities)
        
        # Step 7: Build FHIR parameters from semantic understanding
        fhir_params = self._build_fhir_params_semantic(
            query_semantics, conditions, demographics, 
            temporal_info, numerical_constraints
        )
        
        # Prepare results - convert MedicalEntity objects to JSON-serializable format
        serialized_entities = self._serialize_medical_entities(medical_entities)
        
        results = {
            'original_query': query,
            'nlp_approach': 'biobert_semantic',
            'action': query_semantics.action_type,
            'intent': query_semantics.intent,
            'intent_confidence': query_semantics.confidence,
            'conditions': conditions,
            'demographics': demographics,
            'age_filters': numerical_constraints.get('age_filters', {}),
            'time_filters': temporal_info,
            'medical_entities': serialized_entities,
            'raw_biobert_entities': raw_biobert_entities,  # New: Show full BioBERT capabilities
            'fhir_params': fhir_params,
            'processing_metadata': {
                'entities_found': len(medical_entities),
                'conditions_mapped': len(conditions),
                'raw_entities_detected': len(raw_biobert_entities),
                'semantic_confidence': self._calculate_overall_confidence(
                    query_semantics, conditions, demographics
                )
            }
        }
        
        logger.info(f"‚úÖ BioBERT processing complete. Found {len(conditions)} conditions, confidence: {results['processing_metadata']['semantic_confidence']:.3f}")
        
        return results
    
    def _extract_medical_entities(self, query: str) -> List[MedicalEntity]:
        """Extract medical entities using BioBERT NER pipeline"""
        entities = []
        
        if self.ner_pipeline:
            try:
                # Run NER pipeline
                ner_results = self.ner_pipeline(query)
                
                for entity in ner_results:
                    # Map NER labels to medical entity types
                    entity_type = self._map_ner_label_to_medical_type(entity['entity_group'])
                    
                    medical_entity = MedicalEntity(
                        text=entity['word'],
                        entity_type=entity_type,
                        confidence=float(entity['score']),
                        start_pos=entity['start'],
                        end_pos=entity['end']
                    )
                    
                    entities.append(medical_entity)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è NER extraction failed: {e}")
        
        # Fallback: extract medical entities using semantic similarity
        if not entities:
            entities = self._extract_entities_by_similarity(query)
        
        return entities
    
    def _map_ner_label_to_medical_type(self, ner_label: str) -> str:
        """Map NER labels to medical entity types"""
        label_mapping = {
            'DISEASE': 'CONDITION',
            'CHEMICAL': 'MEDICATION', 
            'GENE': 'BIOMARKER',
            'SPECIES': 'ORGANISM',
            'CELLLINE': 'CELL_TYPE',
            'CELLTYPE': 'CELL_TYPE',
            'DNA': 'GENETIC',
            'RNA': 'GENETIC',
            'PROTEIN': 'BIOMARKER'
        }
        
        return label_mapping.get(ner_label.upper(), 'GENERAL_MEDICAL')
    
    def _extract_entities_by_similarity(self, query: str) -> List[MedicalEntity]:
        """Extract entities using semantic similarity as fallback"""
        entities = []
        query_embedding = self._get_embedding(query)
        
        for concept, data in self.condition_embeddings.items():
            similarity = cosine_similarity(
                [query_embedding], 
                [data['embedding']]
            )[0][0]
            
            if float(similarity) > 0.6:  # Lower threshold for entity detection
                # Find the best matching synonym in the query
                best_match = ""
                best_score = 0
                
                for synonym in data['metadata']['synonyms']:
                    if synonym.lower() in query.lower():
                        synonym_embedding = self._get_embedding(synonym)
                        syn_similarity = cosine_similarity(
                            [query_embedding], [synonym_embedding]
                        )[0][0]
                        
                        if float(syn_similarity) > best_score:
                            best_score = float(syn_similarity)
                            best_match = synonym
                
                if best_match:
                    # Find position in query
                    start_pos = query.lower().find(best_match.lower())
                    end_pos = start_pos + len(best_match) if start_pos != -1 else 0
                    
                    entity = MedicalEntity(
                        text=best_match,
                        entity_type='CONDITION',
                        confidence=float(similarity),
                        start_pos=start_pos,
                        end_pos=end_pos,
                        icd_code=data['metadata'].get('icd10'),
                        snomed_code=data['metadata'].get('snomed'),
                        umls_cui=data['metadata'].get('umls')
                    )
                    
                    entities.append(entity)
        
        return entities
    
    def _extract_raw_biobert_entities(self, query: str) -> List[Dict[str, Any]]:
        """Extract raw BioBERT entities to showcase full model capabilities"""
        raw_entities = []
        
        if self.ner_pipeline:
            try:
                # Run NER pipeline and capture all entities
                ner_results = self.ner_pipeline(query)
                
                for entity in ner_results:
                    raw_entity = {
                        'text': entity['word'],
                        'label': entity['entity_group'],
                        'confidence': float(entity['score']),
                        'start': entity['start'],
                        'end': entity['end'],
                        'mapped_type': self._map_ner_label_to_medical_type(entity['entity_group']),
                        'source': 'BioBERT-NER'
                    }
                    raw_entities.append(raw_entity)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Raw NER extraction failed: {e}")
                # Add fallback message
                raw_entities = [{
                    'text': 'NER extraction failed',
                    'label': 'ERROR',
                    'confidence': 0.0,
                    'start': 0,
                    'end': 0,
                    'mapped_type': 'ERROR',
                    'source': 'Error',
                    'error': str(e)
                }]
        else:
            # No NER pipeline available
            raw_entities = [{
                'text': 'BioBERT NER pipeline not available',
                'label': 'UNAVAILABLE',
                'confidence': 0.0,
                'start': 0,
                'end': 0,
                'mapped_type': 'UNAVAILABLE',
                'source': 'System'
            }]
        
        return raw_entities
    
    def _classify_query_intent(self, query: str) -> QuerySemantics:
        """Classify query intent using semantic similarity with templates"""
        query_embedding = self._get_embedding(query)
        
        best_intent = "search_patients"
        best_score = 0.0
        best_action = "search"
        best_resource = "Patient"
        
        for intent_name, intent_data in self.intent_templates.items():
            # Calculate similarity with each template
            template_scores = []
            
            for template in intent_data['templates']:
                template_embedding = self._get_embedding(template)
                similarity = cosine_similarity(
                    [query_embedding], [template_embedding]
                )[0][0]
                template_scores.append(float(similarity))
            
            # Use max similarity with confidence boost
            max_template_score = max(template_scores)
            boosted_score = max_template_score + intent_data.get('confidence_boost', 0)
            
            if boosted_score > best_score:
                best_score = boosted_score
                best_intent = intent_name
                best_action = intent_data['action']
                best_resource = intent_data['resource']
        
        # Extract modifiers from query
        modifiers = self._extract_query_modifiers(query, query_embedding)
        
        return QuerySemantics(
            intent=best_intent,
            confidence=float(min(best_score, 1.0)),
            action_type=best_action,
            target_resource=best_resource,
            modifiers=modifiers
        )
    
    def _extract_query_modifiers(self, query: str, query_embedding: np.ndarray) -> Dict[str, Any]:
        """Extract query modifiers using semantic understanding"""
        modifiers = {}
        
        # Time-based modifiers
        time_patterns = {
            "recent": ["recently", "latest", "current", "new", "fresh"],
            "past_year": ["last year", "past year", "previous year", "within year"],
            "past_month": ["last month", "past month", "recent month", "this month"],
            "historical": ["historical", "old", "previous", "former", "past"]
        }
        
        for time_type, time_terms in time_patterns.items():
            for term in time_terms:
                term_embedding = self._get_embedding(term)
                similarity = cosine_similarity(
                    [query_embedding], [term_embedding]
                )[0][0]
                
                if float(similarity) > 0.7 or term.lower() in query.lower():
                    modifiers['time_context'] = time_type
                    break
        
        # Severity modifiers
        severity_patterns = {
            "severe": ["severe", "critical", "acute", "serious", "grave"],
            "mild": ["mild", "minor", "slight", "light", "moderate"],
            "chronic": ["chronic", "persistent", "long-term", "ongoing"]
        }
        
        for severity_type, severity_terms in severity_patterns.items():
            for term in severity_terms:
                if term.lower() in query.lower():
                    modifiers['severity'] = severity_type
                    break
        
        # Scope modifiers
        if any(word in query.lower() for word in ["all", "every", "total", "complete"]):
            modifiers['scope'] = "comprehensive"
        elif any(word in query.lower() for word in ["some", "few", "several"]):
            modifiers['scope'] = "limited"
        
        return modifiers
    
    def _extract_demographics_semantic(self, query: str) -> Dict[str, Any]:
        """Extract demographic information using semantic similarity"""
        demographics = {}
        query_embedding = self._get_embedding(query)
        
        # Gender detection using semantic similarity
        gender_concepts = {
            "male": ["male", "man", "men", "gentleman", "masculine", "boy", "guy"],
            "female": ["female", "woman", "women", "lady", "ladies", "feminine", "girl", "gal"]
        }
        
        # Track best gender match to avoid premature breaking
        best_gender = None
        best_gender_confidence = 0.0
        
        for gender, terms in gender_concepts.items():
            for term in terms:
                term_embedding = self._get_embedding(term)
                similarity = cosine_similarity(
                    [query_embedding], [term_embedding]
                )[0][0]
                
                # Check for direct presence in query or high similarity
                if float(similarity) > self.demographic_threshold or term.lower() in query.lower():
                    # Only update if this is a better match
                    if float(similarity) > best_gender_confidence:
                        best_gender = gender
                        best_gender_confidence = float(similarity)
        
        # Set the best gender match found
        if best_gender:
            demographics['gender'] = best_gender
            demographics['gender_confidence'] = best_gender_confidence
        
        # Age group detection using semantic similarity
        age_concepts = {
            "pediatric": ["child", "children", "pediatric", "kid", "infant", "baby", "toddler"],
            "adolescent": ["teenager", "adolescent", "teen", "youth", "young adult"],
            "adult": ["adult", "grown-up", "middle-aged", "mature"],
            "elderly": ["elderly", "senior", "geriatric", "old", "aged", "older adult"]
        }
        
        for age_group, terms in age_concepts.items():
            for term in terms:
                if term.lower() in query.lower():
                    demographics['age_group'] = age_group
                    break
            
            if 'age_group' in demographics:
                break
        
        return demographics
    
    def _extract_temporal_semantic(self, query: str) -> Dict[str, Any]:
        """Extract temporal information using semantic understanding"""
        temporal_info = {}
        query_lower = query.lower()
        
        # Temporal patterns with semantic understanding
        temporal_concepts = {
            "recently": {
                "days": 90,
                "keywords": ["recently", "lately", "currently", "now", "present", "new"]
            },
            "last_month": {
                "days": 30,
                "keywords": ["last month", "past month", "recent month", "this month"]
            },
            "last_year": {
                "days": 365,
                "keywords": ["last year", "past year", "previous year", "annual"]
            },
            "last_week": {
                "days": 7,
                "keywords": ["last week", "past week", "recent week", "weekly"]
            }
        }
        
        for temporal_type, data in temporal_concepts.items():
            for keyword in data['keywords']:
                if keyword in query_lower:
                    cutoff_date = datetime.now() - timedelta(days=data['days'])
                    temporal_info['after_date'] = cutoff_date.strftime('%Y-%m-%d')
                    temporal_info['time_phrase'] = temporal_type
                    temporal_info['days_back'] = data['days']
                    break
            
            if temporal_info:
                break
        
        return temporal_info
    
    def _extract_numerical_constraints(self, query: str) -> Dict[str, Any]:
        """Extract numerical constraints using BioBERT understanding"""
        constraints = {}
        
        # Age patterns using regex combined with semantic understanding
        age_patterns = [
            r'over (\d+)',
            r'above (\d+)', 
            r'older than (\d+)',
            r'under (\d+)',
            r'below (\d+)',
            r'younger than (\d+)',
            r'between (\d+) and (\d+)',
            r'ages? (\d+)-(\d+)',
            r'(\d+) to (\d+) years old',
            r'(\d+)\+ years',
            r'age (\d+)'
        ]
        
        age_filters = {}
        
        for pattern in age_patterns:
            match = re.search(pattern, query.lower())
            if match:
                if 'over' in pattern or 'above' in pattern or 'older' in pattern or '+' in pattern:
                    age_filters['min_age'] = int(match.group(1))
                elif 'under' in pattern or 'below' in pattern or 'younger' in pattern:
                    age_filters['max_age'] = int(match.group(1))
                elif 'between' in pattern or '-' in pattern or 'to' in pattern:
                    age_filters['min_age'] = int(match.group(1))
                    age_filters['max_age'] = int(match.group(2))
                elif 'age' in pattern:
                    # Specific age
                    age_filters['exact_age'] = int(match.group(1))
                break
        
        if age_filters:
            constraints['age_filters'] = age_filters
        
        # Count constraints  
        count_patterns = [
            r'(\d+) patients',
            r'first (\d+)',
            r'top (\d+)',
            r'limit (\d+)',
            r'maximum (\d+)'
        ]
        
        for pattern in count_patterns:
            match = re.search(pattern, query.lower())
            if match:
                constraints['max_results'] = int(match.group(1))
                break
        
        return constraints
    
    def _map_to_medical_conditions(self, query: str, entities: List[MedicalEntity]) -> List[Dict[str, Any]]:
        """Map query and entities to medical conditions using semantic similarity"""
        conditions = []
        query_embedding = self._get_embedding(query)
        
        # First, use entities from NER if available
        entity_conditions = set()
        for entity in entities:
            if entity.entity_type == 'CONDITION' and entity.icd_code:
                conditions.append({
                    'text': entity.text,
                    'code': entity.icd_code,
                    'system': 'http://hl7.org/fhir/sid/icd-10-cm',
                    'confidence': entity.confidence,
                    'method': 'biobert_ner',
                    'snomed_code': entity.snomed_code,
                    'umls_cui': entity.umls_cui
                })
                entity_conditions.add(entity.text.lower())
        
        # Then, use semantic similarity for additional conditions
        for concept, data in self.condition_embeddings.items():
            concept_embedding = data['embedding']
            similarity = cosine_similarity(
                [query_embedding], [concept_embedding]
            )[0][0]
            
            # Check if already found by NER
            concept_text = concept.replace('_', ' ')
            if concept_text.lower() not in entity_conditions:
                
                # Find the best matching synonym actually present in query
                best_synonym = self._find_best_matching_synonym(
                    query, data['metadata']['synonyms']
                )
                
                # Include condition if either similarity is high OR synonym match is found
                if best_synonym or float(similarity) > self.condition_threshold:
                    # Use higher confidence for exact synonym matches
                    final_confidence = max(float(similarity), 0.9) if best_synonym else float(similarity)
                    
                    conditions.append({
                        'text': best_synonym or concept_text,
                        'code': data['metadata']['icd10'],
                        'system': 'http://hl7.org/fhir/sid/icd-10-cm',
                        'confidence': final_confidence,
                        'method': 'biobert_synonym' if best_synonym else 'biobert_semantic',
                        'snomed_code': data['metadata'].get('snomed'),
                        'umls_cui': data['metadata'].get('umls'),
                        'category': data['metadata'].get('category')
                    })
        
        # Sort by confidence
        conditions = sorted(conditions, key=lambda x: x['confidence'], reverse=True)
        
        return conditions
    
    def _find_best_matching_synonym(self, query: str, synonyms: List[str]) -> Optional[str]:
        """Find the best matching synonym present in the query"""
        query_lower = query.lower()
        
        # First, look for exact matches
        for synonym in synonyms:
            if synonym.lower() in query_lower:
                return synonym
        
        # Then, look for partial matches (all words present)
        for synonym in synonyms:
            words = synonym.lower().split()
            if all(word in query_lower for word in words):
                return synonym
        
        # Finally, check for key medical term combinations
        # Special handling for "lung cancer" pattern
        if "lung" in query_lower and "cancer" in query_lower:
            for synonym in synonyms:
                if "lung" in synonym.lower() and ("cancer" in synonym.lower() or "carcinoma" in synonym.lower() or "tumor" in synonym.lower() or "neoplasm" in synonym.lower()):
                    return synonym
        
        # Special handling for "myocardial" pattern
        if "myocardial" in query_lower and ("infarction" in query_lower or "infarct" in query_lower):
            for synonym in synonyms:
                if "myocardial" in synonym.lower() and ("infarction" in synonym.lower() or "infarct" in synonym.lower()):
                    return synonym
        
        return None
    
    def _build_fhir_params_semantic(self, semantics: QuerySemantics, conditions: List[Dict], 
                                   demographics: Dict, temporal_info: Dict, 
                                   constraints: Dict) -> Dict[str, Any]:
        """Build FHIR parameters using semantic understanding"""
        
        fhir_params = {
            'resource_type': semantics.target_resource,
            'search_params': {},
            'include': [],
            'revinclude': [],
            'sort': [],
            'summary': None,
            'elements': [],
            'count': 20
        }
        
        search_params = {}
        
        # Demographics
        if 'gender' in demographics:
            search_params['gender'] = demographics['gender']
        
        # Age filters
        age_filters = constraints.get('age_filters', {})
        if age_filters:
            current_year = datetime.now().year
            
            if 'min_age' in age_filters:
                max_birth_year = current_year - age_filters['min_age']
                search_params['birthdate'] = f"le{max_birth_year}-12-31"
            
            if 'max_age' in age_filters:
                min_birth_year = current_year - age_filters['max_age']
                if 'birthdate' in search_params:
                    # Combine with existing birthdate filter
                    search_params['birthdate'] = [
                        search_params['birthdate'],
                        f"ge{min_birth_year}-01-01"
                    ]
                else:
                    search_params['birthdate'] = f"ge{min_birth_year}-01-01"
            
            if 'exact_age' in age_filters:
                birth_year = current_year - age_filters['exact_age']
                search_params['birthdate'] = [
                    f"ge{birth_year}-01-01",
                    f"le{birth_year}-12-31"
                ]
        
        # Conditions
        if conditions:
            if semantics.action_type == 'count':
                fhir_params['resource_type'] = 'Condition'
                condition_codes = []
                for condition in conditions:
                    condition_codes.append(f"{condition['system']}|{condition['code']}")
                search_params['code'] = ','.join(condition_codes)
                fhir_params['summary'] = 'count'
                fhir_params['count'] = 0
                
            else:
                # Patient search with conditions
                if len(conditions) == 1:
                    condition = conditions[0]
                    search_params['_has:Condition:patient:code'] = f"{condition['system']}|{condition['code']}"
                else:
                    # Multiple conditions
                    condition_strings = []
                    for condition in conditions:
                        condition_strings.append(f"{condition['system']}|{condition['code']}")
                    search_params['_has:Condition:patient:code'] = ','.join(condition_strings)
        
        # Temporal filters
        if temporal_info:
            if 'after_date' in temporal_info:
                if conditions:
                    search_params['_has:Condition:patient:onset-date'] = f"ge{temporal_info['after_date']}"
                else:
                    search_params['_lastUpdated'] = f"ge{temporal_info['after_date']}"
        
        # Result count
        if 'max_results' in constraints:
            fhir_params['count'] = constraints['max_results']
        elif semantics.action_type == 'count':
            fhir_params['count'] = 0
        else:
            # Determine count based on intent
            if semantics.modifiers.get('scope') == 'comprehensive':
                fhir_params['count'] = 100
            elif semantics.modifiers.get('scope') == 'limited':
                fhir_params['count'] = 10
            else:
                fhir_params['count'] = 20
        
        # Sorting
        if fhir_params['resource_type'] == 'Patient':
            fhir_params['sort'] = ['family', 'given']
        elif fhir_params['resource_type'] == 'Condition':
            fhir_params['sort'] = ['-recorded-date']
        
        fhir_params['search_params'] = search_params
        
        return fhir_params
    
    def _get_embedding(self, text: str) -> np.ndarray:
        """Get embedding for text using sentence transformer"""
        if self.sentence_transformer:
            return self.sentence_transformer.encode(text)
        else:
            # Fallback to BioBERT
            inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
            with torch.no_grad():
                outputs = self.biobert_model(**inputs)
                embedding = outputs.last_hidden_state[:, 0, :].numpy()
            return embedding.flatten()
    
    def _calculate_overall_confidence(self, semantics: QuerySemantics, 
                                    conditions: List[Dict], demographics: Dict) -> float:
        """Calculate overall confidence in semantic extraction"""
        confidence = 0.0
        
        # Base confidence from intent classification
        confidence += semantics.confidence * 0.3
        
        # Condition confidence
        if conditions:
            avg_condition_confidence = sum(c['confidence'] for c in conditions) / len(conditions)
            confidence += avg_condition_confidence * 0.5
        
        # Demographics confidence
        if demographics:
            demo_confidence = demographics.get('gender_confidence', 0.8)
            confidence += demo_confidence * 0.2
        
        # Ensure confidence is between 0 and 1
        return float(min(max(confidence, 0.1), 1.0))
    
    def _serialize_medical_entities(self, entities: List[MedicalEntity]) -> List[Dict[str, Any]]:
        """Convert MedicalEntity objects to JSON-serializable dictionaries"""
        serialized = []
        for entity in entities:
            serialized.append({
                'text': entity.text,
                'entity_type': entity.entity_type,
                'confidence': float(entity.confidence),
                'start_pos': entity.start_pos,
                'end_pos': entity.end_pos,
                'icd_code': entity.icd_code,
                'snomed_code': entity.snomed_code,
                'umls_cui': entity.umls_cui
            })
        return serialized
    
    def get_example_queries(self) -> List[Dict[str, Any]]:
        """Return example queries optimized for BioBERT processing"""
        return [
            {
                'query': 'Find patients with myocardial infarction over 65 years old',
                'expected_features': {
                    'intent': 'search_patients',
                    'conditions': ['myocardial_infarction'],
                    'age_constraint': {'min_age': 65},
                    'complexity': 'high'
                }
            },
            {
                'query': 'Count elderly women with diabetes and cardiovascular disease',
                'expected_features': {
                    'intent': 'count_patients', 
                    'conditions': ['diabetes_mellitus', 'cardiovascular_disease'],
                    'demographics': {'gender': 'female', 'age_group': 'elderly'},
                    'complexity': 'high'
                }
            },
            {
                'query': 'Show me patients diagnosed with lung cancer recently',
                'expected_features': {
                    'intent': 'search_patients',
                    'conditions': ['lung_cancer'],
                    'temporal': 'recently',
                    'complexity': 'medium'
                }
            },
            {
                'query': 'Analyze depression and anxiety patterns in young adults',
                'expected_features': {
                    'intent': 'analyze_conditions',
                    'conditions': ['major_depressive_disorder', 'generalized_anxiety_disorder'],
                    'demographics': {'age_group': 'young_adult'},
                    'complexity': 'high'
                }
            },
        ]


# Test the BioBERT NLP processor
if __name__ == "__main__":
    try:
        # Initialize BioBERT processor
        processor = BioBERTHealthcareNLP()
        
        # Test with example queries
        examples = processor.get_example_queries()
        
        print("üß¨ BioBERT Healthcare NLP Processor - Testing")
        print("=" * 60)
        
        for i, example in enumerate(examples, 1):
            print(f"\n--- Example {i} ---")
            print(f"Query: {example['query']}")
            print(f"Complexity: {example['expected_features']['complexity']}")
            
            # Process query
            result = processor.process_query(example['query'])
            
            print(f"‚úÖ Intent: {result['intent']} (confidence: {result['intent_confidence']:.3f})")
            print(f"‚úÖ Action: {result['action']}")
            print(f"‚úÖ Conditions Found: {len(result['conditions'])}")
            
            for condition in result['conditions']:
                method = condition.get('method', 'unknown')
                conf = condition['confidence']
                print(f"   - {condition['text']} ({condition['code']}) [{method}] conf:{conf:.3f}")
            
            print(f"‚úÖ Demographics: {result['demographics']}")
            print(f"‚úÖ Age Filters: {result['age_filters']}")
            print(f"‚úÖ FHIR Resource: {result['fhir_params']['resource_type']}")
            print(f"‚úÖ Overall Confidence: {result['processing_metadata']['semantic_confidence']:.3f}")
            
    except Exception as e:
        print(f"‚ùå Error testing BioBERT processor: {e}")
        import traceback
        traceback.print_exc()
